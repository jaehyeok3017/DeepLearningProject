{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmInbLySmkgF",
        "outputId": "a0e8b3d9-6d17-490d-d465-ad62e6a81783"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=6ccf46dc2ca46081f0671839f40297862a6feed3a1d2562650bbd07b25d3cbf6\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4phek_Bml9X7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras import layers, models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, metrics\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP7k_uoYl9X8",
        "outputId": "ad0494a5-75f6-451b-a6cc-fe79312a3dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_dir = \"/content/drive/My Drive/DeepLearningProject/model/data\"\n",
        "categories = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sTQ7DUfal9X8"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 40):\n",
        "    categories.append(f\"{i}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f8jStzll9X8",
        "outputId": "23026b88-4cbd-4f5b-98bf-107131fb02ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39']\n"
          ]
        }
      ],
      "source": [
        "print(categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMnRLJVDl9X9",
        "outputId": "eaaa4d0c-d8a5-4b7e-aa27-5489f764c7cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1  :  /content/drive/My Drive/DeepLearningProject/model/data/1/1_0_2_20161219211823957.jpg.chip.jpg\n",
            "1  :  /content/drive/My Drive/DeepLearningProject/model/data/1/1_0_2_20161219203016316.jpg.chip.jpg\n",
            "2  :  /content/drive/My Drive/DeepLearningProject/model/data/2/2_1_2_20161219140736641.jpg.chip.jpg\n",
            "3  :  /content/drive/My Drive/DeepLearningProject/model/data/3/3_1_2_20161219140825328.jpg.chip.jpg\n",
            "4  :  /content/drive/My Drive/DeepLearningProject/model/data/4/4_0_2_20161219140938368.jpg.chip.jpg\n",
            "5  :  /content/drive/My Drive/DeepLearningProject/model/data/5/5_0_2_20161219142128680.jpg.chip.jpg\n",
            "6  :  /content/drive/My Drive/DeepLearningProject/model/data/6/6_1_2_20161219140554092.jpg.chip.jpg\n",
            "7  :  /content/drive/My Drive/DeepLearningProject/model/data/7/7_1_2_20161219141129768.jpg.chip.jpg\n",
            "8  :  /content/drive/My Drive/DeepLearningProject/model/data/8/8_1_2_20161219153017828.jpg.chip.jpg\n",
            "9  :  /content/drive/My Drive/DeepLearningProject/model/data/9/9_1_2_20161219190524395.jpg.chip.jpg\n",
            "10  :  /content/drive/My Drive/DeepLearningProject/model/data/10/10_0_3_20161220215952636.jpg.chip.jpg\n",
            "11  :  /content/drive/My Drive/DeepLearningProject/model/data/11/11_0_0_20170103200824775.jpg.chip.jpg\n",
            "12  :  /content/drive/My Drive/DeepLearningProject/model/data/12/12_1_3_20161220222343139.jpg.chip.jpg\n",
            "13  :  /content/drive/My Drive/DeepLearningProject/model/data/13/13_0_0_20170103200413990.jpg.chip.jpg\n",
            "14  :  /content/drive/My Drive/DeepLearningProject/model/data/14/14_1_3_20161220220655004.jpg.chip.jpg\n",
            "15  :  /content/drive/My Drive/DeepLearningProject/model/data/15/15_1_2_20161219190855506.jpg.chip.jpg\n",
            "16  :  /content/drive/My Drive/DeepLearningProject/model/data/16/16_0_4_20161221200238647.jpg.chip.jpg\n",
            "17  :  /content/drive/My Drive/DeepLearningProject/model/data/17/17_0_3_20161219224759672.jpg.chip.jpg\n",
            "18  :  /content/drive/My Drive/DeepLearningProject/model/data/18/18_1_2_20170102234846172.jpg.chip.jpg\n",
            "19  :  /content/drive/My Drive/DeepLearningProject/model/data/19/19_0_2_20170102234958195.jpg.chip.jpg\n",
            "20  :  /content/drive/My Drive/DeepLearningProject/model/data/20/20_0_4_20170102233239947.jpg.chip.jpg\n",
            "21  :  /content/drive/My Drive/DeepLearningProject/model/data/21/21_1_2_20161219211717693.jpg.chip.jpg\n",
            "22  :  /content/drive/My Drive/DeepLearningProject/model/data/22/22_1_3_20161220221656537.jpg.chip.jpg\n",
            "23  :  /content/drive/My Drive/DeepLearningProject/model/data/23/23_1_1_20170102233446754.jpg.chip.jpg\n",
            "24  :  /content/drive/My Drive/DeepLearningProject/model/data/24/24_0_2_20161219190613907.jpg.chip.jpg\n",
            "25  :  /content/drive/My Drive/DeepLearningProject/model/data/25/25_0_2_20161219193843611.jpg.chip.jpg\n",
            "26  :  /content/drive/My Drive/DeepLearningProject/model/data/26/26_1_0_20170116234743292.jpg.chip.jpg\n",
            "26  :  /content/drive/My Drive/DeepLearningProject/model/data/26/26_1_0_20170116184549800.jpg.chip.jpg\n",
            "26  :  /content/drive/My Drive/DeepLearningProject/model/data/26/26_0_1_20170113152741498.jpg.chip.jpg\n",
            "27  :  /content/drive/My Drive/DeepLearningProject/model/data/27/27_1_0_20170103181541352.jpg.chip.jpg\n",
            "28  :  /content/drive/My Drive/DeepLearningProject/model/data/28/28_0_2_20161219192654931.jpg.chip.jpg\n",
            "29  :  /content/drive/My Drive/DeepLearningProject/model/data/29/29_0_0_20170102233617277.jpg.chip.jpg\n",
            "30  :  /content/drive/My Drive/DeepLearningProject/model/data/30/30_0_2_20161219190337805.jpg.chip.jpg\n",
            "31  :  /content/drive/My Drive/DeepLearningProject/model/data/31/31_0_2_20161219192759515.jpg.chip.jpg\n",
            "32  :  /content/drive/My Drive/DeepLearningProject/model/data/32/32_1_2_20170103183806483.jpg.chip.jpg\n",
            "33  :  /content/drive/My Drive/DeepLearningProject/model/data/33/33_1_0_20170103163004757.jpg.chip.jpg\n",
            "34  :  /content/drive/My Drive/DeepLearningProject/model/data/34/34_1_0_20170103163016663.jpg.chip.jpg\n",
            "35  :  /content/drive/My Drive/DeepLearningProject/model/data/35/35_1_0_20170103163453110.jpg.chip.jpg\n",
            "36  :  /content/drive/My Drive/DeepLearningProject/model/data/36/36_1_3_20161220221952627.jpg.chip.jpg\n",
            "37  :  /content/drive/My Drive/DeepLearningProject/model/data/37/37_0_0_20170102233603627.jpg.chip.jpg\n",
            "38  :  /content/drive/My Drive/DeepLearningProject/model/data/38/38_1_0_20170103163517069.jpg.chip.jpg\n",
            "39  :  /content/drive/My Drive/DeepLearningProject/model/data/39/39_1_0_20170103163234408.jpg.chip.jpg\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(categories)\n",
        "\n",
        "image_w = 100\n",
        "image_h = 100\n",
        "\n",
        "pixels = image_w * image_h * 3\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for idx, category in enumerate(categories):\n",
        "    label = [0 for i in range(num_classes)]\n",
        "    label[idx] = 1\n",
        "\n",
        "    image_dir = data_dir + \"/\" + category\n",
        "    files = glob(image_dir + \"/*.jpg\")\n",
        "\n",
        "    for i,f in enumerate(files):\n",
        "        img = Image.open(f)\n",
        "        img = img.convert(\"RGB\")\n",
        "        img = img.resize((image_w, image_h))\n",
        "        data = np.asarray(img)\n",
        "\n",
        "        x.append(data)\n",
        "        y.append(label)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(category, \" : \", f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5DBWwaoVl9X-"
      },
      "outputs": [],
      "source": [
        "x = np.array(x)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zi6W618ql9X-"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
        "xy = (x_train, x_test, y_train, y_test)\n",
        "\n",
        "#x_train = x_train.astype(float) / 255\n",
        "#x_test = x_test.astype(float) / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saSXpt8Zl9X-",
        "outputId": "3a14b086-115f-4178-85bf-081565ecbfb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "input_tensor = Input(shape=(100, 100, 3), dtype='float32', name='input')\n",
        "\n",
        "#vgg16 모델 불러오기\n",
        "pre_trained_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "pre_trained_vgg.trainable = False\n",
        "pre_trained_vgg.summary()\n",
        "\n",
        "#vgg16 밑에 레이어 추가\n",
        "add_model = models.Sequential()\n",
        "add_model.add(pre_trained_vgg)\n",
        "add_model.add(layers.Flatten())\n",
        "add_model.add(layers.Dense(4096, kernel_regularizer = regularizers.l1_l2\n",
        "                                  (l1=0.001,l2=0.001),activation='relu'))\n",
        "add_model.add(layers.Dropout(0.5))\n",
        "add_model.add(layers.Dense(2048, kernel_regularizer = regularizers.l1_l2\n",
        "                                  (l1=0.001,l2=0.001),activation='relu'))\n",
        "add_model.add(layers.Dropout(0.5))\n",
        "add_model.add(layers.Dense(1024, kernel_regularizer = regularizers.l1_l2\n",
        "                                  (l1=0.001,l2=0.001),activation='relu'))\n",
        "add_model.add(layers.Dropout(0.5))\n",
        "add_model.add(layers.Dense(39, activation='softmax'))\n",
        "\n",
        "add_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_NsxlfLl9YE",
        "outputId": "43bf4aa8-9188-45c8-8116-01b09b639587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              18878464  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2048)              8390656   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 39)                39975     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,121,959\n",
            "Trainable params: 29,407,271\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "add_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcVZplR9l9YE",
        "outputId": "3ce19c36-9a06-47da-c794-c58cb95f50f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "412/412 [==============================] - 43s 72ms/step - loss: 127.6441 - acc: 0.0840 - val_loss: 4.1411 - val_acc: 0.1328\n",
            "Epoch 2/100\n",
            "412/412 [==============================] - 29s 70ms/step - loss: 1.9144 - acc: 0.1145 - val_loss: 1.6330 - val_acc: 0.1328\n",
            "Epoch 3/100\n",
            "412/412 [==============================] - 29s 70ms/step - loss: 1.6282 - acc: 0.1286 - val_loss: 1.6120 - val_acc: 0.1328\n",
            "Epoch 4/100\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.6040 - acc: 0.1325 - val_loss: 1.5910 - val_acc: 0.1328\n",
            "Epoch 5/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5826 - acc: 0.1336 - val_loss: 1.5792 - val_acc: 0.1328\n",
            "Epoch 6/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5793 - acc: 0.1336 - val_loss: 1.5793 - val_acc: 0.1328\n",
            "Epoch 7/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5793 - acc: 0.1336 - val_loss: 1.5792 - val_acc: 0.1328\n",
            "Epoch 8/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5793 - acc: 0.1336 - val_loss: 1.5792 - val_acc: 0.1328\n",
            "Epoch 9/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5793 - acc: 0.1336 - val_loss: 1.5791 - val_acc: 0.1328\n",
            "Epoch 10/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5793 - acc: 0.1336 - val_loss: 1.5791 - val_acc: 0.1328\n",
            "Epoch 11/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5793 - acc: 0.1336 - val_loss: 1.5791 - val_acc: 0.1328\n",
            "Epoch 12/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5790 - val_acc: 0.1328\n",
            "Epoch 13/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5793 - acc: 0.1336 - val_loss: 1.5791 - val_acc: 0.1328\n",
            "Epoch 14/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5791 - val_acc: 0.1328\n",
            "Epoch 15/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5793 - acc: 0.1336 - val_loss: 1.5790 - val_acc: 0.1328\n",
            "Epoch 16/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5790 - val_acc: 0.1328\n",
            "Epoch 17/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5790 - val_acc: 0.1328\n",
            "Epoch 18/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 19/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 20/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 21/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5790 - val_acc: 0.1328\n",
            "Epoch 22/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5787 - val_acc: 0.1328\n",
            "Epoch 23/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 24/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 25/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 26/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 27/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 28/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 29/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 30/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 31/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 32/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 33/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 34/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 35/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 36/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 37/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 38/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 39/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 40/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 41/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 42/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 43/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 44/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 45/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 46/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 47/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 48/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 49/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 50/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 51/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 52/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 53/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5787 - val_acc: 0.1328\n",
            "Epoch 54/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 55/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 56/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 57/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 58/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 59/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 60/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 61/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 62/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 63/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5789 - val_acc: 0.1328\n",
            "Epoch 64/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 65/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 66/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 67/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 68/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 69/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 70/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5787 - val_acc: 0.1328\n",
            "Epoch 71/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 72/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 73/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5787 - val_acc: 0.1328\n",
            "Epoch 74/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 75/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5787 - val_acc: 0.1328\n",
            "Epoch 76/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5787 - val_acc: 0.1328\n",
            "Epoch 77/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 78/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5787 - val_acc: 0.1328\n",
            "Epoch 79/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 80/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 81/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 82/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 83/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 84/100\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 85/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 86/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 87/100\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 88/100\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 89/100\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 90/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 91/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 92/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 93/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 94/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 95/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 96/100\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5787 - val_acc: 0.1328\n",
            "Epoch 97/100\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 98/100\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 99/100\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n",
            "Epoch 100/100\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1336 - val_loss: 1.5788 - val_acc: 0.1328\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b3c7015d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "add_model.fit(x_train, y_train, \n",
        "                    batch_size=30, \n",
        "                    epochs=100, \n",
        "                    validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cSo7Wy0bl9YF"
      },
      "outputs": [],
      "source": [
        "model_json = add_model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file : \n",
        "    json_file.write(model_json)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
      }
    },
    "colab": {
      "name": "model.ipynb의 사본",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}