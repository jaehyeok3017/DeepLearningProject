{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmInbLySmkgF",
        "outputId": "0ff75fa5-7b87-45ee-df6c-e5af72e63dae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4phek_Bml9X7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras import layers, models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, metrics\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP7k_uoYl9X8",
        "outputId": "b91faf08-8fe5-4d17-dd9e-2c6e81aaf17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_dir = \"/content/drive/My Drive/DeepLearningProject/model/data\"\n",
        "categories = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sTQ7DUfal9X8"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 40):\n",
        "    categories.append(f\"{i}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f8jStzll9X8",
        "outputId": "52308db3-d339-4deb-b235-fe9b1f0c7e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39']\n"
          ]
        }
      ],
      "source": [
        "print(categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMnRLJVDl9X9",
        "outputId": "c4f81900-e35c-4093-fc5e-54d057e5c24c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1  :  /content/drive/My Drive/DeepLearningProject/model/data/1/1_0_2_20161219211823957.jpg.chip.jpg\n",
            "1  :  /content/drive/My Drive/DeepLearningProject/model/data/1/1_0_2_20161219203016316.jpg.chip.jpg\n",
            "2  :  /content/drive/My Drive/DeepLearningProject/model/data/2/2_1_2_20161219140736641.jpg.chip.jpg\n",
            "3  :  /content/drive/My Drive/DeepLearningProject/model/data/3/3_1_2_20161219140825328.jpg.chip.jpg\n",
            "4  :  /content/drive/My Drive/DeepLearningProject/model/data/4/4_0_2_20161219140938368.jpg.chip.jpg\n",
            "5  :  /content/drive/My Drive/DeepLearningProject/model/data/5/5_0_2_20161219142128680.jpg.chip.jpg\n",
            "6  :  /content/drive/My Drive/DeepLearningProject/model/data/6/6_1_2_20161219140554092.jpg.chip.jpg\n",
            "7  :  /content/drive/My Drive/DeepLearningProject/model/data/7/7_1_2_20161219141129768.jpg.chip.jpg\n",
            "8  :  /content/drive/My Drive/DeepLearningProject/model/data/8/8_1_2_20161219153017828.jpg.chip.jpg\n",
            "9  :  /content/drive/My Drive/DeepLearningProject/model/data/9/9_1_2_20161219190524395.jpg.chip.jpg\n",
            "10  :  /content/drive/My Drive/DeepLearningProject/model/data/10/10_0_3_20161220215952636.jpg.chip.jpg\n",
            "11  :  /content/drive/My Drive/DeepLearningProject/model/data/11/11_0_0_20170103200824775.jpg.chip.jpg\n",
            "12  :  /content/drive/My Drive/DeepLearningProject/model/data/12/12_1_3_20161220222343139.jpg.chip.jpg\n",
            "13  :  /content/drive/My Drive/DeepLearningProject/model/data/13/13_0_0_20170103200413990.jpg.chip.jpg\n",
            "14  :  /content/drive/My Drive/DeepLearningProject/model/data/14/14_1_3_20161220220655004.jpg.chip.jpg\n",
            "15  :  /content/drive/My Drive/DeepLearningProject/model/data/15/15_1_2_20161219190855506.jpg.chip.jpg\n",
            "16  :  /content/drive/My Drive/DeepLearningProject/model/data/16/16_0_4_20161221200238647.jpg.chip.jpg\n",
            "17  :  /content/drive/My Drive/DeepLearningProject/model/data/17/17_0_3_20161219224759672.jpg.chip.jpg\n",
            "18  :  /content/drive/My Drive/DeepLearningProject/model/data/18/18_1_2_20170102234846172.jpg.chip.jpg\n",
            "19  :  /content/drive/My Drive/DeepLearningProject/model/data/19/19_0_2_20170102234958195.jpg.chip.jpg\n",
            "20  :  /content/drive/My Drive/DeepLearningProject/model/data/20/20_0_4_20170102233239947.jpg.chip.jpg\n",
            "21  :  /content/drive/My Drive/DeepLearningProject/model/data/21/21_1_2_20161219211717693.jpg.chip.jpg\n",
            "22  :  /content/drive/My Drive/DeepLearningProject/model/data/22/22_1_3_20161220221656537.jpg.chip.jpg\n",
            "23  :  /content/drive/My Drive/DeepLearningProject/model/data/23/23_1_1_20170102233446754.jpg.chip.jpg\n",
            "24  :  /content/drive/My Drive/DeepLearningProject/model/data/24/24_0_2_20161219190613907.jpg.chip.jpg\n",
            "25  :  /content/drive/My Drive/DeepLearningProject/model/data/25/25_0_2_20161219193843611.jpg.chip.jpg\n",
            "26  :  /content/drive/My Drive/DeepLearningProject/model/data/26/26_1_0_20170116234743292.jpg.chip.jpg\n",
            "26  :  /content/drive/My Drive/DeepLearningProject/model/data/26/26_1_0_20170116184549800.jpg.chip.jpg\n",
            "26  :  /content/drive/My Drive/DeepLearningProject/model/data/26/26_0_1_20170113152741498.jpg.chip.jpg\n",
            "27  :  /content/drive/My Drive/DeepLearningProject/model/data/27/27_1_0_20170103181541352.jpg.chip.jpg\n",
            "28  :  /content/drive/My Drive/DeepLearningProject/model/data/28/28_0_2_20161219192654931.jpg.chip.jpg\n",
            "29  :  /content/drive/My Drive/DeepLearningProject/model/data/29/29_0_0_20170102233617277.jpg.chip.jpg\n",
            "30  :  /content/drive/My Drive/DeepLearningProject/model/data/30/30_0_2_20161219190337805.jpg.chip.jpg\n",
            "31  :  /content/drive/My Drive/DeepLearningProject/model/data/31/31_0_2_20161219192759515.jpg.chip.jpg\n",
            "32  :  /content/drive/My Drive/DeepLearningProject/model/data/32/32_1_2_20170103183806483.jpg.chip.jpg\n",
            "33  :  /content/drive/My Drive/DeepLearningProject/model/data/33/33_1_0_20170103163004757.jpg.chip.jpg\n",
            "34  :  /content/drive/My Drive/DeepLearningProject/model/data/34/34_1_0_20170103163016663.jpg.chip.jpg\n",
            "35  :  /content/drive/My Drive/DeepLearningProject/model/data/35/35_1_0_20170103163453110.jpg.chip.jpg\n",
            "36  :  /content/drive/My Drive/DeepLearningProject/model/data/36/36_1_3_20161220221952627.jpg.chip.jpg\n",
            "37  :  /content/drive/My Drive/DeepLearningProject/model/data/37/37_0_0_20170102233603627.jpg.chip.jpg\n",
            "38  :  /content/drive/My Drive/DeepLearningProject/model/data/38/38_1_0_20170103163517069.jpg.chip.jpg\n",
            "39  :  /content/drive/My Drive/DeepLearningProject/model/data/39/39_1_0_20170103163234408.jpg.chip.jpg\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(categories)\n",
        "\n",
        "image_w = 100\n",
        "image_h = 100\n",
        "\n",
        "pixels = image_w * image_h * 3\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for idx, category in enumerate(categories):\n",
        "    label = [0 for i in range(num_classes)]\n",
        "    label[idx] = 1\n",
        "\n",
        "    image_dir = data_dir + \"/\" + category\n",
        "    files = glob(image_dir + \"/*.jpg\")\n",
        "\n",
        "    for i,f in enumerate(files):\n",
        "        img = Image.open(f)\n",
        "        img = img.convert(\"RGB\")\n",
        "        img = img.resize((image_w, image_h))\n",
        "        data = np.asarray(img)\n",
        "\n",
        "        x.append(data)\n",
        "        y.append(label)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(category, \" : \", f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5DBWwaoVl9X-"
      },
      "outputs": [],
      "source": [
        "x = np.array(x)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zi6W618ql9X-"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
        "xy = (x_train, x_test, y_train, y_test)\n",
        "\n",
        "#x_train = x_train.astype(float) / 255\n",
        "#x_test = x_test.astype(float) / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saSXpt8Zl9X-",
        "outputId": "73ec2f44-8dcb-47bc-e3e4-172f65562272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "input_tensor = Input(shape=(100, 100, 3), dtype='float32', name='input')\n",
        "\n",
        "#vgg16 모델 불러오기\n",
        "pre_trained_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "pre_trained_vgg.trainable = False\n",
        "pre_trained_vgg.summary()\n",
        "\n",
        "#vgg16 밑에 레이어 추가\n",
        "add_model = models.Sequential()\n",
        "add_model.add(pre_trained_vgg)\n",
        "add_model.add(layers.Flatten())\n",
        "add_model.add(layers.Dense(4096, kernel_regularizer = regularizers.l1_l2\n",
        "                                  (l1=0.001,l2=0.001),activation='relu'))\n",
        "add_model.add(layers.Dropout(0.5))\n",
        "add_model.add(layers.Dense(2048, kernel_regularizer = regularizers.l1_l2\n",
        "                                  (l1=0.001,l2=0.001),activation='relu'))\n",
        "add_model.add(layers.Dropout(0.5))\n",
        "add_model.add(layers.Dense(1024, kernel_regularizer = regularizers.l1_l2\n",
        "                                  (l1=0.001,l2=0.001),activation='relu'))\n",
        "add_model.add(layers.Dropout(0.5))\n",
        "add_model.add(layers.Dense(39, activation='softmax'))\n",
        "\n",
        "add_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_NsxlfLl9YE",
        "outputId": "c6798e74-424b-462e-ada4-741ba4eb0ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              18878464  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2048)              8390656   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 39)                39975     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,121,959\n",
            "Trainable params: 29,407,271\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "add_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcVZplR9l9YE",
        "outputId": "96b431a4-bf77-49e5-f520-18fa488ab0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "412/412 [==============================] - 41s 73ms/step - loss: 127.7285 - acc: 0.0874 - val_loss: 4.1342 - val_acc: 0.1408\n",
            "Epoch 2/500\n",
            "412/412 [==============================] - 29s 70ms/step - loss: 1.9141 - acc: 0.1134 - val_loss: 1.6313 - val_acc: 0.1408\n",
            "Epoch 3/500\n",
            "412/412 [==============================] - 29s 70ms/step - loss: 1.6267 - acc: 0.1262 - val_loss: 1.6087 - val_acc: 0.1408\n",
            "Epoch 4/500\n",
            "412/412 [==============================] - 29s 70ms/step - loss: 1.6021 - acc: 0.1308 - val_loss: 1.5889 - val_acc: 0.1408\n",
            "Epoch 5/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5815 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 6/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5793 - acc: 0.1309 - val_loss: 1.5792 - val_acc: 0.1408\n",
            "Epoch 7/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 8/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 9/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 10/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 11/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 12/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 13/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 14/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 15/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 16/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 17/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5792 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 18/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 19/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 20/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 21/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 22/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 23/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 24/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 25/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 26/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 27/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 28/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 29/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 30/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 31/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 32/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 33/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 34/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 35/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 36/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 37/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 38/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 39/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 40/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 41/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 42/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 43/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 44/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 45/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 46/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 47/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 48/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 49/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 50/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 51/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 52/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 53/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 54/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 55/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 56/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 57/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 58/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 59/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 60/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 61/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 62/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 63/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 64/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 65/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 66/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 67/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 68/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 69/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 70/500\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 71/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 72/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 73/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 74/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 75/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 76/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 77/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5791 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 78/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 79/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 80/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 81/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 82/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 83/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 84/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 85/500\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 86/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 87/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 88/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 89/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 90/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 91/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 92/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 93/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 94/500\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 95/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 96/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 97/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 98/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 99/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 100/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 101/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 102/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 103/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 104/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 105/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 106/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 107/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 108/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 109/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 110/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 111/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 112/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 113/500\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 114/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 115/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 116/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 117/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 118/500\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 119/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 120/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 121/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 122/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 123/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 124/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 125/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 126/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 127/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 128/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 129/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 130/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 131/500\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 132/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 133/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 134/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 135/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 136/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 137/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 138/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 139/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 140/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 141/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 142/500\n",
            "412/412 [==============================] - 34s 84ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 143/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 144/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 145/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 146/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 147/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 148/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 149/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 150/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 151/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 152/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 153/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 154/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 155/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 156/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 157/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 158/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 159/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 160/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 161/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 162/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 163/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 164/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 165/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 166/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 167/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 168/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 169/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 170/500\n",
            "412/412 [==============================] - 34s 84ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 171/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 172/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 173/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 174/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 175/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 176/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 177/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 178/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 179/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 180/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 181/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 182/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 183/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 184/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 185/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 186/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 187/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 188/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 189/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 190/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5788 - val_acc: 0.1408\n",
            "Epoch 191/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 192/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 193/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 194/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 195/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 196/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 197/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 198/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 199/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 200/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 201/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 202/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 203/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 204/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 205/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 206/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 207/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 208/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 209/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 210/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 211/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 212/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 213/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 214/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 215/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 216/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 217/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 218/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 219/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 220/500\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 221/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 222/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 223/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 224/500\n",
            "412/412 [==============================] - 34s 84ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 225/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 226/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 227/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 228/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 229/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 230/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 231/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 232/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 233/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 234/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 235/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 236/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 237/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 238/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 239/500\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 240/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 241/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 242/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 243/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 244/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 245/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 246/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 247/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 248/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 249/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 250/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 251/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 252/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 253/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 254/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5788 - val_acc: 0.1408\n",
            "Epoch 255/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 256/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5788 - val_acc: 0.1408\n",
            "Epoch 257/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 258/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 259/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 260/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 261/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 262/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 263/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 264/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 265/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 266/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 267/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 268/500\n",
            "412/412 [==============================] - 35s 84ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 269/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 270/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 271/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5792 - val_acc: 0.1408\n",
            "Epoch 272/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 273/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 274/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 275/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 276/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 277/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 278/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 279/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 280/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 281/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 282/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 283/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 284/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 285/500\n",
            "412/412 [==============================] - 30s 73ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 286/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 287/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 288/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 289/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 290/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 291/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 292/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 293/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 294/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 295/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 296/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 297/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 298/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 299/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 300/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 301/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 302/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 303/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 304/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 305/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 306/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 307/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 308/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 309/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 310/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 311/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 312/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 313/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 314/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 315/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 316/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 317/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 318/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 319/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 320/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 321/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 322/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 323/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 324/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 325/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 326/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 327/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 328/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 329/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 330/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 331/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 332/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 333/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 334/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 335/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 336/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 337/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 338/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 339/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5791 - val_acc: 0.1408\n",
            "Epoch 340/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 341/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 342/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 343/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 344/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 345/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 346/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 347/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 348/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 349/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 350/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 351/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 352/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 353/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 354/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 355/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5792 - val_acc: 0.1408\n",
            "Epoch 356/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 357/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 358/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 359/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 360/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 361/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 362/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5789 - val_acc: 0.1408\n",
            "Epoch 363/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 364/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 365/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 366/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 367/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 368/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 369/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 370/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 371/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 372/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 373/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 374/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 375/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 376/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 377/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 378/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 379/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 380/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 381/500\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 382/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 383/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 384/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 385/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 386/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 387/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 388/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 389/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 390/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 391/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 392/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 393/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 394/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 395/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 396/500\n",
            "412/412 [==============================] - 34s 84ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 397/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 398/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 399/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 400/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 401/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 402/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 403/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 404/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 405/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 406/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 407/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 408/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 409/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 410/500\n",
            "412/412 [==============================] - 34s 83ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 411/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 412/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 413/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 414/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 415/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 416/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 417/500\n",
            "412/412 [==============================] - 30s 73ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 418/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 419/500\n",
            "412/412 [==============================] - 34s 84ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 420/500\n",
            "412/412 [==============================] - 29s 71ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 421/500\n",
            "412/412 [==============================] - 29s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 422/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 423/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 424/500\n",
            "412/412 [==============================] - 30s 72ms/step - loss: 1.5790 - acc: 0.1309 - val_loss: 1.5790 - val_acc: 0.1408\n",
            "Epoch 425/500\n",
            "243/412 [================>.............] - ETA: 10s - loss: 1.5789 - acc: 0.1329"
          ]
        }
      ],
      "source": [
        "add_model.fit(x_train, y_train, \n",
        "                    batch_size=30, \n",
        "                    epochs=500, \n",
        "                    validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "cSo7Wy0bl9YF",
        "outputId": "6be4a84c-855c-41d3-9216-b3ed41bcbb58"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3dcbfa0e4e0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'additional_model' is not defined"
          ]
        }
      ],
      "source": [
        "model_json = add_model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file : \n",
        "    json_file.write(model_json)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
      }
    },
    "colab": {
      "name": "model.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}