{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from keras import layers, models\n",
    "from keras.applications import VGG16\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "categories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 40):\n",
    "    categories.append(f\"{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39']\n"
     ]
    }
   ],
   "source": [
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  :  ./data/1\\1_0_0_20161219140623097.jpg.chip.jpg\n",
      "1  :  ./data/1\\1_1_3_20161220143211359.jpg.chip.jpg\n",
      "2  :  ./data/2\\2_0_0_20161219154008997.jpg.chip.jpg\n",
      "3  :  ./data/3\\3_0_0_20161219154520213.jpg.chip.jpg\n",
      "4  :  ./data/4\\4_0_0_20161219192808843.jpg.chip.jpg\n",
      "5  :  ./data/5\\5_0_0_20170103205053570.jpg.chip.jpg\n",
      "6  :  ./data/6\\6_0_0_20170110213109002.jpg.chip.jpg\n",
      "7  :  ./data/7\\7_0_0_20161219201514284.jpg.chip.jpg\n",
      "8  :  ./data/8\\8_0_0_20170103200436055.jpg.chip.jpg\n",
      "9  :  ./data/9\\9_0_0_20170102235106821.jpg.chip.jpg\n",
      "10  :  ./data/10\\10_0_0_20161220222308131.jpg.chip.jpg\n",
      "11  :  ./data/11\\11_0_0_20170103200509559.jpg.chip.jpg\n",
      "12  :  ./data/12\\12_0_0_20170103200900511.jpg.chip.jpg\n",
      "13  :  ./data/13\\13_0_0_20170103200413990.jpg.chip.jpg\n",
      "14  :  ./data/14\\14_0_0_20170102234323550.jpg.chip.jpg\n",
      "15  :  ./data/15\\15_0_0_20170102234355667.jpg.chip.jpg\n",
      "16  :  ./data/16\\16_0_0_20170102234641453.jpg.chip.jpg\n",
      "17  :  ./data/17\\17_0_0_20170103201439825.jpg.chip.jpg\n",
      "18  :  ./data/18\\18_0_0_20170103201308008.jpg.chip.jpg\n",
      "19  :  ./data/19\\19_0_0_20170102233014401.jpg.chip.jpg\n",
      "20  :  ./data/20\\20_0_0_20170104020603909.jpg.chip.jpg\n",
      "21  :  ./data/21\\21_0_0_20170102233225196.jpg.chip.jpg\n",
      "22  :  ./data/22\\22_0_0_20170103180152583.jpg.chip.jpg\n",
      "23  :  ./data/23\\23_0_0_20170104004006925.jpg.chip.jpg\n",
      "24  :  ./data/24\\24_0_0_20170102233329675.jpg.chip.jpg\n",
      "25  :  ./data/25\\25_0_0_20170102233320979.jpg.chip.jpg\n",
      "26  :  ./data/26\\26_0_0_20170102233359482.jpg.chip.jpg\n",
      "26  :  ./data/26\\26_1_0_20170110173815028.jpg.chip.jpg\n",
      "26  :  ./data/26\\26_1_3_20170119180605476.jpg.chip.jpg\n",
      "27  :  ./data/27\\27_0_0_20170102233409115.jpg.chip.jpg\n",
      "28  :  ./data/28\\28_0_0_20170102233520314.jpg.chip.jpg\n",
      "29  :  ./data/29\\29_0_0_20170102233617277.jpg.chip.jpg\n",
      "30  :  ./data/30\\30_0_0_20170103181149464.jpg.chip.jpg\n",
      "31  :  ./data/31\\31_0_0_20170103183951893.jpg.chip.jpg\n",
      "32  :  ./data/32\\32_0_0_20170103182544874.jpg.chip.jpg\n",
      "33  :  ./data/33\\33_0_0_20170104165103473.jpg.chip.jpg\n",
      "34  :  ./data/34\\34_0_0_20170103182629265.jpg.chip.jpg\n",
      "35  :  ./data/35\\35_0_0_20170103182703466.jpg.chip.jpg\n",
      "36  :  ./data/36\\36_0_0_20170103180815064.jpg.chip.jpg\n",
      "37  :  ./data/37\\37_0_0_20170102233603627.jpg.chip.jpg\n",
      "38  :  ./data/38\\38_0_0_20170103183142330.jpg.chip.jpg\n",
      "39  :  ./data/39\\39_0_0_20170103183230555.jpg.chip.jpg\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(categories)\n",
    "\n",
    "image_w = 300\n",
    "image_h = 400\n",
    "\n",
    "pixels = image_w * image_h * 3\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for idx, category in enumerate(categories):\n",
    "    label = [0 for i in range(num_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = data_dir + \"/\" + category\n",
    "    files = glob(image_dir + \"/*.jpg\")\n",
    "\n",
    "    for i,f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        x.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(category, \" : \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.52 GiB for an array with shape (16472, 400, 300, 3) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\AI\\DeepLearningProject\\model\\model.ipynb 셀 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/AI/DeepLearningProject/model/model.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/AI/DeepLearningProject/model/model.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.52 GiB for an array with shape (16472, 400, 300, 3) and data type uint8"
     ]
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 47.6 GiB for an array with shape (17763, 400, 300, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\AI\\DeepLearningProject\\model\\model.ipynb 셀 7\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/AI/DeepLearningProject/model/model.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(x, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/AI/DeepLearningProject/model/model.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m xy \u001b[39m=\u001b[39m (x_train, x_test, y_train, y_test)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/AI/DeepLearningProject/model/model.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x_train \u001b[39m=\u001b[39m x_train\u001b[39m.\u001b[39;49mastype(\u001b[39mfloat\u001b[39;49m) \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/AI/DeepLearningProject/model/model.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m x_test \u001b[39m=\u001b[39m x_test\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 47.6 GiB for an array with shape (17763, 400, 300, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "xy = (x_train, x_test, y_train, y_test)\n",
    "\n",
    "x_train = x_train.astype(float) / 255\n",
    "x_test = x_test.astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(400, 300, 3), dtype='float32', name='input')\n",
    "\n",
    "#vgg16 모델 불러오기\n",
    "pre_trained_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(400, 300, 3))\n",
    "pre_trained_vgg.trainable = False\n",
    "pre_trained_vgg.summary()\n",
    "\n",
    "#vgg16 밑에 레이어 추가\n",
    "additional_model = models.Sequential()\n",
    "additional_model.add(pre_trained_vgg)\n",
    "additional_model.add(layers.Flatten())\n",
    "additional_model.add(layers.Dense(4096, kernel_regularizer = regularizers.l1_l2\n",
    "                                  (l1=0.001,l2=0.001),activation='relu'))\n",
    "additional_model.add(layers.Dropout(0.5))\n",
    "additional_model.add(layers.Dense(2048, kernel_regularizer = regularizers.l1_l2\n",
    "                                  (l1=0.001,l2=0.001),activation='relu'))\n",
    "additional_model.add(layers.Dropout(0.5))\n",
    "additional_model.add(layers.Dense(1024, kernel_regularizer = regularizers.l1_l2\n",
    "                                  (l1=0.001,l2=0.001),activation='relu'))\n",
    "additional_model.add(layers.Dropout(0.5))\n",
    "additional_model.add(layers.Dense(12, activation='softmax'))\n",
    "\n",
    "additional_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 222, 222, 128)     3584      \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 220, 220, 128)     147584    \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 218, 218, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 108, 108, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 106, 106, 128)     147584    \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 104, 104, 128)     147584    \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 102, 102, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 50, 50, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 48, 48, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 46, 46, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 44, 44, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 21, 21, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 19, 19, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 17, 17, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " age (Dense)                 (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,858,369\n",
      "Trainable params: 34,858,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "additional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "additional_model.fit(x_train, y_train, \n",
    "                    batch_size=50, \n",
    "                    epochs=500, \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16579, 224, 224, 3) 4\n",
      "(16579, 100) 2\n"
     ]
    }
   ],
   "source": [
    "model_json = additional_model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
